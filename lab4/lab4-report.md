#### University: [ITMO University](https://itmo.ru/ru/)
#### Faculty: [FTMI](https://ftmi.itmo.ru/)
#### Course: [Cloud platforms as the basis of technology entrepreneurship]
#### Year: 2023/2024
#### Group: U4225
#### Author: Kovalev Taras Andreevich
#### Lab: Lab4
#### Date of create: 07.11.2024
#### Date of finished: 

## Приложение для обработки и анализа текстовых документов с использованием технологий искусственного интеллекта "DocMate"

## Описание
Это четвертая лабораторная работа "Разработка инфраструктуры MVP AI приложения.

## Цель работы
Создать прототип AI-приложения с базовой функциональностью.

## Функциональность:

Загрузка документов (PDF, DOCX, текстовых файлов).

Обработка документов с помощью предобученных моделей для извлечения ключевых данных (например, даты, суммы, наименования компаний и т. д.).

Возможность поиска по извлеченной информации.

Вывод данных в формате JSON для дальнейшего использования.

## Ход работы


## Архитектура AI-приложения будет состоять из следующих компонентов:

**Пользовательский интерфейс (Frontend)**
Интерфейс позволит пользователям загружать документы, просматривать результаты и искать по данным. Веб-приложение будет разработано с использованием React.js или Angular.

**API-сервер**
API-сервер будет обрабатывать запросы от пользователя, передавать их в AI-модуль и отправлять результаты обратно. Для реализации API можно использовать Python (Flask/Django) или FastAPI для асинхронных запросов.

**AI-сервис для обработки документов**
AI-сервис будет извлекать данные и считать метрики из документов с использованием моделей NLP (например, Hugging Face Transformers или spaCy). Архитектура позволит добавлять новые сервисы по мере роста нагрузки. Балансировщик нагрузки будет распределять запросы между сервисами.

**Хранилище метрик (Metrics Storage)**
Метрики и результаты обработки будут храниться в базе данных (PostgreSQL или MongoDB для неструктурированных данных). Для ускорения отклика можно использовать кэш (например, Redis). В зависимости от сценария, данные будут извлекаться из хранилища или напрямую передаваться в AI-сервис.

**Облачные ресурсы**
Для масштабируемости приложения будут использоваться облачные платформы (AWS, Google Cloud), виртуальные машины (EC2), контейнеризация через Docker и Kubernetes, а также хранилище файлов (например, S3).

**Система логирования и мониторинга**
Мониторинг будет осуществляться с помощью Prometheus и Grafana, а логирование — через ELK Stack или Datadog. Система авторизации будет вынесена в отдельный сервис для разгрузки API, что повысит производительность и безопасность.

## 7. Схема инфраструктуры:
<img width="843" alt="image" src="https://github.com/user-attachments/assets/93fed6a5-0b01-47f3-9ff2-4ab0c853d487">

1. Пользователь загружает документы через веб-интерфейс(FrontEnd)
2. Запрос поступает на API-сервер, который передает его на обработку в AI-модуль.
3. Далее я использую AI service - элемент, который берет файлы,считает метрики и дает ответ. Можно встроить в архитектуру столько подобных сервисов, сколько понадобится; можно также считать разные метрики на разных сервисах. При этом, API не важно, какой сервис чем занят, за это отвечает модуль Balancer.

На cхеме данные приходят в API, он же их складывает в хранилище(Metrics Storage) и отправляет запрос на обработку, Balancer ищет свободные сервисы и просит их обработать данные (больше запросов - больше сервисов - расширяемо). 

Далее по разным сценариям:

**(А)** Сервисы возьмут файлы из хранилища, посчитают метрики и сложат в БД. 

**(Б)** Шлем данные напрямую из AI в сервисы, а сервисы всё посчитают, сложат файлы в хранилище и метрики в бд, но тогда у сервисов появляется больше задач, а это отнимает работу у AI API. 

В **Metrics Storage** можно добавить кэш (например, AI API -> Metrics станет AI API -> Cache -> Metrics), чтобы хранить последние добавленные данные в БД или часто используемые, просто чтобы отклик ускорить

**Авторизация** будет выноситься отдельным сервисом, чтобы не нагружать API. 


## Экономическая модель и обоснование выбора ресурсов

**Пользовательский интерфейс (Frontend):** На старте приложения с низкой нагрузкой можно использовать недорогие облачные решения - React.js или Angular.
**Стоимость:** хостинг на AWS S3 — $0,023/GB в месяц.

**API-сервер (Backend):**  Flask/Django или FastAPI.
**Стоимость:** хостинг на AWS EC2 (t2.micro) — $8 в месяц, AWS Fargate для контейнеров — от $0,04048/час.

**AI Service:** Для такой задачи подойдут контейнеры на AWS ECS или Google Cloud Kubernetes.
**Стоимость:** сервер с 2 vCPU, 8 GB RAM — $40-$50 в месяц.

**Balancer** Когда нагрузка увеличится, потребуется масштабируемая инфраструктура. Подойдет AWS ELB или Google Cloud Load Balancer.
**Стоимость:** AWS ELB — $0,025/GB за обработку данных.

**Metrics Storage:** AWS RDS (PostgreSQL) или Google Cloud SQL для баз данных, AWS ElastiCache для кэширования (Redis).
**Стоимость:** AWS RDS — $15-20 в месяц, ElastiCache — $15-50 в месяц.

**Для AI-сервисов и хранения файлов** используется AWS EC2 и Amazon S3.
**Стоимость:** AWS EC2 (t2.micro) — $8 в месяц, Amazon S3 — $0,023/GB в месяц.

**Для системы авторизации** используется Auth0.
**Стоимость:** Auth0 — $23 в месяц на 1000 пользователей.

**Логирование и мониторинг:** Используются Prometheus и Grafana для мониторинга, Datadog или ELK Stack для логирования.
**Стоимость:** Prometheus/Grafana — бесплатно, Datadog/ELK Stack — от $15 в месяц.

## Итоговая оценка (начальная стадия):
Базовые расходы (API, AI-сервис, хостинг, базы данных) составляют $100-150 в месяц. Масштабирование увеличит стоимость в зависимости от нагрузки.

## Заключение

Архитектура AI-приложения должна быть гибкой и масштабируемой, чтобы справляться с ростом нагрузки на разных этапах разработки. На старте можно использовать простые облачные решения, такие как EC2, RDS и базовый API, что позволит снизить затраты.

С ростом приложения и переходом в продакшн понадобятся более сложные компоненты, такие как микросервисы, контейнеризация с Kubernetes, балансировка нагрузки и автоматическое масштабирование для обеспечения стабильной работы при увеличении запросов.

Также важно учесть гибкую экономическую модель, которая позволит масштабировать ресурсы по мере роста нагрузки. В процессе масштабирования расходы на вычисления, хранение данных и мониторинг будут расти в зависимости от количества пользователей и объема данных.
